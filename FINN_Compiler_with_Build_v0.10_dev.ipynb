{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System Check and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CUDA Check\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ba/Xilinx/finn-0v10-dev/finn/notebooks/batuhan\n"
     ]
    }
   ],
   "source": [
    "# Path Check\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folding_flag = 'custom'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline and Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "1. [Introduction to  `build_dataflow` Tool](#intro_build_dataflow) \n",
    "2. [Understanding the Build Configuration: `DataflowBuildConfig`](#underst_build_conf)     \n",
    "    2.1.[Output Products](#output_prod)   \n",
    "    2.2.[Configuring the Board and FPGA Part](#config_fpga)   \n",
    "    2.3 [Configuring the Performance](#config_perf)    \n",
    "4. [Launch a Build: Only Estimate Reports](#build_estimate_report)\n",
    "5. [Launch a Build: Stitched IP, out-of-context synth and rtlsim Performance](#build_ip_synth_rtlsim)\n",
    "6. [(Optional) Launch a Build: PYNQ Bitfile and Driver](#build_bitfile_driver)\n",
    "7. [(Optional) Run on PYNQ board](#run_on_pynq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Build Configuration: `DataflowBuildConfig` <a id=\"underst_build_conf\"></a>\n",
    "\n",
    "The build configuration is specified by an instance of `finn.builder.build_dataflow_config.DataflowBuildConfig`. The configuration is a Python [`dataclass`](https://docs.python.org/3/library/dataclasses.html) which can be serialized into or de-serialized from JSON files for persistence, although we'll just set it up in Python here.\n",
    "There are many options in the configuration to customize different aspects of the build, we'll only cover a few of them in this notebook. You can read the details on all the config options on [the FINN API documentation](https://finn-dev.readthedocs.io/en/latest/source_code/finn.builder.html#finn.builder.build_dataflow_config.DataflowBuildConfig).\n",
    "\n",
    "Let's go over some of the members of the `DataflowBuildConfig`:\n",
    "\n",
    "### Output Products <a id=\"output_prod\"></a>\n",
    "\n",
    "The build can produce many different outputs, and some of them can take a long time (e.g. bitfile synthesis for a large network). When you first start working on generating a new accelerator and exploring the different performance options, you may not want to go all the way to a bitfile. Thus, in the beginning you may just select the estimate reports as the output products. Gradually, you can generate the output products from later stages until you are happy enough with the design to build the full accelerator integrated into a shell.\n",
    "\n",
    "The output products are controlled by:\n",
    "\n",
    "* `generate_outputs`: list of output products (of type [`finn.builder.build_dataflow_config.DataflowOutputType`](https://finn-dev.readthedocs.io/en/latest/source_code/finn.builder.html#finn.builder.build_dataflow_config.DataflowOutputType)) that will be generated by the build. Some available options are:\n",
    "    - `ESTIMATE_REPORTS` : report expected resources and performance per layer and for the whole network without any synthesis\n",
    "    - `STITCHED_IP` : create a stream-in stream-out IP design that can be integrated into other Vivado IPI or RTL designs\n",
    "    - `RTLSIM_PERFORMANCE` : use PyVerilator to do a performance/latency test of the `STITCHED_IP` design\n",
    "    - `OOC_SYNTH` : run out-of-context synthesis (just the accelerator itself, without any system surrounding it) on the `STITCHED_IP` design to get post-synthesis FPGA resources and achievable clock frequency\n",
    "    - `BITFILE` : integrate the accelerator into a shell to produce a standalone bitfile\n",
    "    - `PYNQ_DRIVER` : generate a PYNQ Python driver that can be used to launch the accelerator\n",
    "    - `DEPLOYMENT_PACKAGE` : create a folder with the `BITFILE` and `PYNQ_DRIVER` outputs, ready to be copied to the target FPGA platform.\n",
    "* `output_dir`: the directory where all the generated build outputs above will be written into.\n",
    "* `steps`: list of predefined (or custom) build steps FINN will go through. Use `build_dataflow_config.estimate_only_dataflow_steps` to execute only the steps needed for estimation (without any synthesis), and the `build_dataflow_config.default_build_dataflow_steps` otherwise (which is the default value). You can find the list of default steps [here](https://finn.readthedocs.io/en/latest/source_code/finn.builder.html#finn.builder.build_dataflow_config.default_build_dataflow_steps) in the documentation.\n",
    "\n",
    "### Configuring the Board and FPGA Part <a id=\"config_fpga\"></a>\n",
    "\n",
    "* `fpga_part`: Xilinx FPGA part to be used for synthesis, can be left unspecified to be inferred from `board` below, or specified explicitly for e.g. out-of-context synthesis.\n",
    "* `board`: target Xilinx Zynq or Alveo board for generating accelerators integrated into a shell. See the `pynq_part_map` and `alveo_part_map` dicts in [this file](https://github.com/Xilinx/finn-base/blob/dev/src/finn/util/basic.py#L41) for a list of possible boards.\n",
    "* `shell_flow_type`: the target [shell flow type](https://finn-dev.readthedocs.io/en/latest/source_code/finn.builder.html#finn.builder.build_dataflow_config.ShellFlowType), only needed for generating full bitfiles where the FINN design is integrated into a shell (so only needed if `BITFILE` is selected) \n",
    "\n",
    "### Configuring the Performance <a id=\"config_perf\"></a>\n",
    "\n",
    "You can configure the performance (and correspondingly, the FPGA resource footprint) of the generated dataflow accelerator in two ways:\n",
    "\n",
    "1) (basic) Set a target performance and let the compiler figure out the per-node parallelization settings.\n",
    "\n",
    "2) (advanced) Specify a separate .json as `folding_config_file` that lists the degree of parallelization (as well as other hardware options) for each layer.\n",
    "\n",
    "This notebook only deals with the basic approach, for which you need to set up:\n",
    "\n",
    "* `target_fps`: target inference performance in frames per second. Note that target may not be achievable due to specific layer constraints, or due to resource limitations of the FPGA. \n",
    "* `synth_clk_period_ns`: target clock frequency (in nanoseconds) for Vivado synthesis. e.g. `synth_clk_period_ns=5.0` will target a 200 MHz clock. Note that the target clock period may not be achievable depending on the FPGA part and design complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch a Build: Only Estimate Reports <a id=\"build_estimate_report\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "First, we'll launch a build that only generates the estimate reports, which does not require any synthesis. Note two things below: how the `generate_outputs` only contains `ESTIMATE_REPORTS`, but also how the `steps` uses a value of `estimate_only_dataflow_steps`. This skips steps like HLS synthesis to provide a quick estimate from analytical models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ba/Xilinx/finn-0v10/finn/notebooks/batuhan\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"/home/ba/Xilinx/finn-0v10/finn/notebooks/batuhan\"\n",
    "print(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = model_dir+\"/QONNX_CNV.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '/home/ba/Xilinx/finn-0v10/finn/notebooks/batuhan/QONNX_CNV.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fc2001c8670>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "showInNetron(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous run results deleted!\n"
     ]
    }
   ],
   "source": [
    "estimates_output_dir = \"output_estimates_only\"\n",
    "\n",
    "#Delete previous run results if exist\n",
    "if os.path.exists(estimates_output_dir):\n",
    "    shutil.rmtree(estimates_output_dir)\n",
    "    print(\"Previous run results deleted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folding Mode is Custom\n",
      "{\n",
      " \"Defaults\": {},\n",
      " \"ConvolutionInputGenerator_rtl_0\": {\n",
      "  \"SIMD\": 1,\n",
      "  \"parallel_window\": 0,\n",
      "  \"ram_style\": \"distributed\"\n",
      " },\n",
      " \"MVAU_hls_0\": {\n",
      "  \"PE\": 1,\n",
      "  \"SIMD\": 27,\n",
      "  \"ram_style\": \"auto\",\n",
      "  \"resType\": \"auto\",\n",
      "  \"mem_mode\": \"internal_decoupled\",\n",
      "  \"runtime_writeable_weights\": 0\n",
      " },\n",
      " \"ConvolutionInputGenerator_rtl_1\": {\n",
      "  \"SIMD\": 8,\n",
      "  \"parallel_window\": 0,\n",
      "  \"ram_style\": \"distributed\"\n",
      " },\n",
      " \"MVAU_hls_1\": {\n",
      "  \"PE\": 8,\n",
      "  \"SIMD\": 72,\n",
      "  \"ram_style\": \"auto\",\n",
      "  \"resType\": \"auto\",\n",
      "  \"mem_mode\": \"internal_decoupled\",\n",
      "  \"runtime_writeable_weights\": 0\n",
      " },\n",
      " \"StreamingMaxPool_hls_0\": {\n",
      "  \"PE\": 1\n",
      " },\n",
      " \"ConvolutionInputGenerator_rtl_2\": {\n",
      "  \"SIMD\": 2,\n",
      "  \"parallel_window\": 0,\n",
      "  \"ram_style\": \"distributed\"\n",
      " },\n",
      " \"MVAU_hls_2\": {\n",
      "  \"PE\": 2,\n",
      "  \"SIMD\": 72,\n",
      "  \"ram_style\": \"auto\",\n",
      "  \"resType\": \"auto\",\n",
      "  \"mem_mode\": \"internal_decoupled\",\n",
      "  \"runtime_writeable_weights\": 0\n",
      " },\n",
      " \"ConvolutionInputGenerator_rtl_3\": {\n",
      "  \"SIMD\": 2,\n",
      "  \"parallel_window\": 0,\n",
      "  \"ram_style\": \"distributed\"\n",
      " },\n",
      " \"MVAU_hls_3\": {\n",
      "  \"PE\": 4,\n",
      "  \"SIMD\": 72,\n",
      "  \"ram_style\": \"auto\",\n",
      "  \"resType\": \"auto\",\n",
      "  \"mem_mode\": \"internal_decoupled\",\n",
      "  \"runtime_writeable_weights\": 0\n",
      " },\n",
      " \"StreamingMaxPool_hls_1\": {\n",
      "  \"PE\": 1\n",
      " },\n",
      " \"ConvolutionInputGenerator_rtl_4\": {\n",
      "  \"SIMD\": 1,\n",
      "  \"parallel_window\": 0,\n",
      "  \"ram_style\": \"distributed\"\n",
      " },\n",
      " \"MVAU_hls_4\": {\n",
      "  \"PE\": 1,\n",
      "  \"SIMD\": 32,\n",
      "  \"ram_style\": \"auto\",\n",
      "  \"resType\": \"auto\",\n",
      "  \"mem_mode\": \"internal_decoupled\",\n",
      "  \"runtime_writeable_weights\": 0\n",
      " },\n",
      " \"MVAU_hls_5\": {\n",
      "  \"PE\": 2,\n",
      "  \"SIMD\": 4,\n",
      "  \"ram_style\": \"auto\",\n",
      "  \"resType\": \"auto\",\n",
      "  \"mem_mode\": \"internal_decoupled\",\n",
      "  \"runtime_writeable_weights\": 0\n",
      " },\n",
      " \"MVAU_hls_6\": {\n",
      "  \"PE\": 1,\n",
      "  \"SIMD\": 4,\n",
      "  \"ram_style\": \"auto\",\n",
      "  \"resType\": \"auto\",\n",
      "  \"mem_mode\": \"internal_decoupled\",\n",
      "  \"runtime_writeable_weights\": 0\n",
      " },\n",
      " \"MVAU_hls_7\": {\n",
      "  \"PE\": 1,\n",
      "  \"SIMD\": 1,\n",
      "  \"ram_style\": \"auto\",\n",
      "  \"resType\": \"auto\",\n",
      "  \"mem_mode\": \"internal_decoupled\",\n",
      "  \"runtime_writeable_weights\": 0\n",
      " }\n",
      "}\n",
      "Building dataflow accelerator from /home/ba/Xilinx/finn-0v10/finn/notebooks/batuhan/QONNX_CNV.onnx\n",
      "Intermediate outputs will be generated in /tmp/finn_dev_ba\n",
      "Final outputs will be generated in output_estimates_only\n",
      "Build log is at output_estimates_only/build_dataflow.log\n",
      "Running step: custom_step_add_pre_proc [1/11]\n",
      "Running step: custom_step_add_post_proc [2/11]\n",
      "Running step: step_qonnx_to_finn [3/11]\n",
      "Running step: step_tidy_up [4/11]\n",
      "Running step: step_streamline [5/11]\n",
      "Running step: step_convert_to_hw [6/11]\n",
      "Running step: step_create_dataflow_partition [7/11]\n",
      "Running step: step_specialize_layers [8/11]\n",
      "Running step: step_apply_folding_config [9/11]\n",
      "Running step: step_minimize_bit_width [10/11]\n",
      "Running step: step_generate_estimate_reports [11/11]\n",
      "Completed successfully\n"
     ]
    }
   ],
   "source": [
    "if folding_flag == 'auto':\n",
    "    print(\"Folding Mode is Auto\")\n",
    "\n",
    "    cfg_estimates = build.DataflowBuildConfig(\n",
    "        output_dir          = estimates_output_dir,\n",
    "        mvau_wwidth_max     = 80,\n",
    "        target_fps          = 1000,\n",
    "        synth_clk_period_ns = 10.0,\n",
    "        fpga_part           = \"xc7z020clg400-2\",\n",
    "        steps               = build_cfg.estimate_only_dataflow_steps,\n",
    "        generate_outputs=[\n",
    "            build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "elif folding_flag == 'custom':\n",
    "    print(\"Folding Mode is Custom\")\n",
    "\n",
    "    build_dir = os.environ['FINN_ROOT'] + \"/notebooks/batuhan\"    \n",
    "    import json    \n",
    "    with open(build_dir+\"/custom_folding_config.json\", 'r') as json_file:\n",
    "        folding_config = json.load(json_file)    \n",
    "    print(json.dumps(folding_config, indent=1))\n",
    "\n",
    "    from finn.util.pytorch import ToTensor\n",
    "    from qonnx.transformation.merge_onnx_models import MergeONNXModels\n",
    "    from qonnx.core.modelwrapper import ModelWrapper\n",
    "    from qonnx.core.datatype import DataType\n",
    "    \n",
    "    def custom_step_add_pre_proc(model: ModelWrapper, cfg: build.DataflowBuildConfig):\n",
    "        ishape = model.get_tensor_shape(model.graph.input[0].name)\n",
    "        # preprocessing: torchvision's ToTensor divides uint8 inputs by 255\n",
    "        preproc = ToTensor()\n",
    "        export_qonnx(preproc, torch.randn(ishape), \"preproc.onnx\", opset_version=11)\n",
    "        preproc_model = ModelWrapper(\"preproc.onnx\")\n",
    "        # set input finn datatype to UINT8\n",
    "        preproc_model.set_tensor_datatype(preproc_model.graph.input[0].name, DataType[\"UINT8\"])\n",
    "        # merge pre-processing onnx model with cnv model (passed as input argument)\n",
    "        model = model.transform(MergeONNXModels(preproc_model))\n",
    "        return model\n",
    "\n",
    "    from qonnx.transformation.insert_topk import InsertTopK\n",
    "    \n",
    "    def custom_step_add_post_proc(model: ModelWrapper, cfg: build.DataflowBuildConfig):\n",
    "        model = model.transform(InsertTopK(k=1))\n",
    "        return model\n",
    "\n",
    "    import torch\n",
    "    from finn.util.test import get_test_model_trained\n",
    "    from brevitas.export import export_qonnx\n",
    "    from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "\n",
    "## Build flow with custom folding configuration\n",
    "## folding_config_file = \"folding_config_all_lutram.json\"\n",
    "\n",
    "    build_steps = [\n",
    "        custom_step_add_pre_proc,\n",
    "        custom_step_add_post_proc,\n",
    "        \"step_qonnx_to_finn\",\n",
    "        \"step_tidy_up\",\n",
    "        \"step_streamline\",\n",
    "        \"step_convert_to_hw\",\n",
    "        \"step_create_dataflow_partition\",\n",
    "        \"step_specialize_layers\",\n",
    "        \"step_apply_folding_config\",\n",
    "        \"step_minimize_bit_width\",\n",
    "        \"step_generate_estimate_reports\",\n",
    "    ]\n",
    "    \n",
    "    cfg_estimates = build.DataflowBuildConfig(\n",
    "        output_dir          = estimates_output_dir,\n",
    "        mvau_wwidth_max     = 80,\n",
    "        synth_clk_period_ns = 10.0,\n",
    "        fpga_part           = \"xc7z020clg400-2\",\n",
    "        steps               = build_steps,\n",
    "        folding_config_file = \"custom_folding_config.json\",\n",
    "        generate_outputs=[\n",
    "            build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    build.build_dataflow_cfg(model_file, cfg_estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(estimates_output_dir + \"/report/estimate_network_performance.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now examine the generated outputs from this build. If we look under the outputs directory, we'll find a subfolder with the generated estimate reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_dataflow.log   report\t\t\t\t     time_per_step.json\n",
      "intermediate_models  template_specialize_layers_config.json\n"
     ]
    }
   ],
   "source": [
    "! ls {estimates_output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimate_layer_config_alternatives.json  estimate_network_performance.json\n",
      "estimate_layer_cycles.json\t\t op_and_param_counts.json\n",
      "estimate_layer_resources.json\n"
     ]
    }
   ],
   "source": [
    "! ls {estimates_output_dir}/report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that various reports have been generated as .json files. Let's examine the contents of the `estimate_network_performance.json` for starters. Here, we can see the analytical estimates for the performance and latency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output directory was created and we can extract information about our model and also how it was processed in the FINN compiler from the generated files. Let's focus on the intermediate models for now. You can find them in the output directory in the folder \"intermediate_models\".\n",
    "\n",
    "Source: 4_advanced_builder_settings.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_step_add_pre_proc.onnx\tdataflow_parent.onnx\n",
      "custom_step_add_post_proc.onnx\tstep_create_dataflow_partition.onnx\n",
      "step_qonnx_to_finn.onnx\t\tstep_specialize_layers.onnx\n",
      "step_tidy_up.onnx\t\tstep_apply_folding_config.onnx\n",
      "step_streamline.onnx\t\tstep_minimize_bit_width.onnx\n",
      "step_convert_to_hw.onnx\t\tstep_generate_estimate_reports.onnx\n",
      "supported_op_partitions\n"
     ]
    }
   ],
   "source": [
    "!ls -t -r {build_dir}/output_estimates_only/intermediate_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"critical_path_cycles\": 733224,\n",
      "  \"max_cycles\": 147456,\n",
      "  \"max_cycles_node_name\": \"MVAU_hls_5\",\n",
      "  \"estimated_throughput_fps\": 678.1684027777778,\n",
      "  \"estimated_latency_ns\": 7332240.0\n",
      "}"
     ]
    }
   ],
   "source": [
    "! cat {estimates_output_dir}/report/estimate_network_performance.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all of these reports are .json files, we can easily load them into Python for further processing. This can be useful if you are building your own design automation tools on top of FINN. Let's define a helper function and look at the `estimate_layer_cycles.json` report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def read_json_dict(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        ret = json.load(f)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Thresholding_rtl_0': 3072,\n",
       " 'ConvolutionInputGenerator_rtl_0': 24501,\n",
       " 'MVAU_hls_0': 57600,\n",
       " 'ConvolutionInputGenerator_rtl_1': 56952,\n",
       " 'MVAU_hls_1': 50176,\n",
       " 'StreamingMaxPool_hls_0': 980,\n",
       " 'ConvolutionInputGenerator_rtl_2': 42464,\n",
       " 'MVAU_hls_2': 73728,\n",
       " 'ConvolutionInputGenerator_rtl_3': 59328,\n",
       " 'MVAU_hls_3': 51200,\n",
       " 'StreamingMaxPool_hls_1': 125,\n",
       " 'ConvolutionInputGenerator_rtl_4': 12032,\n",
       " 'MVAU_hls_4': 82944,\n",
       " 'MVAU_hls_5': 147456,\n",
       " 'MVAU_hls_6': 65536,\n",
       " 'MVAU_hls_7': 5120,\n",
       " 'LabelSelect_hls_0': 10}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_json_dict(estimates_output_dir + \"/report/estimate_layer_cycles.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see the estimated number of clock cycles each layer will take. Recall that all of these layers will be running in parallel, and the slowest layer will determine the overall throughput of the entire neural network. FINN attempts to parallelize each layer such that they all take a similar number of cycles, and less than the corresponding number of cycles that would be required to meet `target_fps`. Additionally by summing up all layer cycle estimates one can obtain an estimate for the overall latency of the whole network. \n",
    "\n",
    "Finally, we can see the layer-by-layer resource estimates in the `estimate_layer_resources.json` report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Thresholding_rtl_0': {'BRAM_18K': 0,\n",
       "  'BRAM_efficiency': 1,\n",
       "  'LUT': 128.0,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'ConvolutionInputGenerator_rtl_0': {'BRAM_18K': 0,\n",
       "  'BRAM_efficiency': 1,\n",
       "  'LUT': 348,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'MVAU_hls_0': {'BRAM_18K': 2,\n",
       "  'BRAM_efficiency': 0.09375,\n",
       "  'LUT': 1788,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'ConvolutionInputGenerator_rtl_1': {'BRAM_18K': 0,\n",
       "  'BRAM_efficiency': 1,\n",
       "  'LUT': 412,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'MVAU_hls_1': {'BRAM_18K': 16,\n",
       "  'BRAM_efficiency': 0.125,\n",
       "  'LUT': 4172,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'StreamingMaxPool_hls_0': {'BRAM_18K': 0,\n",
       "  'BRAM_efficiency': 1,\n",
       "  'LUT': 0,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'ConvolutionInputGenerator_rtl_2': {'BRAM_18K': 0,\n",
       "  'BRAM_efficiency': 1,\n",
       "  'LUT': 354,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'MVAU_hls_2': {'BRAM_18K': 4,\n",
       "  'BRAM_efficiency': 1.0,\n",
       "  'LUT': 1268,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'ConvolutionInputGenerator_rtl_3': {'BRAM_18K': 0,\n",
       "  'BRAM_efficiency': 1,\n",
       "  'LUT': 392,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'MVAU_hls_3': {'BRAM_18K': 8,\n",
       "  'BRAM_efficiency': 1.0,\n",
       "  'LUT': 2240,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'StreamingMaxPool_hls_1': {'BRAM_18K': 0,\n",
       "  'BRAM_efficiency': 1,\n",
       "  'LUT': 0,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'ConvolutionInputGenerator_rtl_4': {'BRAM_18K': 0,\n",
       "  'BRAM_efficiency': 1,\n",
       "  'LUT': 344,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'MVAU_hls_4': {'BRAM_18K': 18,\n",
       "  'BRAM_efficiency': 0.8888888888888888,\n",
       "  'LUT': 521,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'MVAU_hls_5': {'BRAM_18K': 72,\n",
       "  'BRAM_efficiency': 0.8888888888888888,\n",
       "  'LUT': 374,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'MVAU_hls_6': {'BRAM_18K': 16,\n",
       "  'BRAM_efficiency': 0.8888888888888888,\n",
       "  'LUT': 335,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'MVAU_hls_7': {'BRAM_18K': 1,\n",
       "  'BRAM_efficiency': 0.2777777777777778,\n",
       "  'LUT': 315,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'LabelSelect_hls_0': {'BRAM_18K': 0,\n",
       "  'BRAM_efficiency': 1,\n",
       "  'LUT': 0,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'total': {'BRAM_18K': 137.0, 'LUT': 12991.0, 'URAM': 0.0, 'DSP': 0.0}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_json_dict(estimates_output_dir + \"/report/estimate_layer_resources.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This particular report is useful to determine whether the current configuration will fit into a particular FPGA. \n",
    "\n",
    "**Note that the analytical models tend to over-estimate how much resources are needed, since they can't capture the effects of various synthesis optimizations.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pynq-Z2 HW Resources: BRAM_18K: 140 (4.9 Mb), LUT: 53.200, DSP:220"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source \n",
    "https://github.com/Xilinx/finn/blob/e3087ad9fbabcc35f21164d415ababec4f462e9f/notebooks/advanced/3_folding.ipynb#L44\n",
    "\n",
    "My notebook \n",
    "http://127.0.0.1:8888/notebooks/batuhan/3_folding_BA.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_folding_config_file = \"custom_folding_config.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch a Build: Stitched IP, out-of-context synth and rtlsim Performance <a id=\"build_ip_synth_rtlsim\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "\n",
    "Once we have a configuration that gives satisfactory estimates, we can move on to generating the accelerator. We can do this in different ways depending on how we want to integrate the accelerator into a larger system. For instance, if we have a larger streaming system built in Vivado or if we'd like to re-use this generated accelerator as an IP component in other projects, the `STITCHED_IP` output product is a good choice. We can also use the `OOC_SYNTH` output product to get post-synthesis resource and clock frequency numbers for our accelerator.\n",
    "\n",
    "<font color=\"red\">**Live FINN tutorial:** These next builds will take about 10 minutes to complete since multiple calls to Vivado and a call to RTL simulation are involved. While this is running, you can examine the generated files with noVNC -- it is running on **(your AWS URL):6080/vnc.html**\n",
    "\n",
    "* Once the `step_hls_codegen [8/16]` below is completed, you can view the generated HLS code under its own folder for each layer: `/tmp/finn_dev_ubuntu/code_gen_ipgen_MVAU_hls_XXXXXX`\n",
    "    \n",
    "* Once the `step_create_stitched_ip [11/16]` below is completed, you can view the generated stitched IP in Vivado under `/home/ubuntu/finn/notebooks/end2end_example/cybersecurity/output_ipstitch_ooc_rtlsim/stitched_ip`\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous run results deleted!\n"
     ]
    }
   ],
   "source": [
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "model_file = model_dir+\"/QONNX_CNV.onnx\"\n",
    "\n",
    "rtlsim_output_dir = \"output_ipstitch_ooc_rtlsim\"\n",
    "\n",
    "#Delete previous run results if exist\n",
    "if os.path.exists(rtlsim_output_dir):\n",
    "    shutil.rmtree(rtlsim_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "\n",
    "#custom_step_add_pre_proc,\n",
    "#custom_step_add_post_proc,\n",
    "\n",
    "build_steps = [\n",
    "    \"step_qonnx_to_finn\",\n",
    "    \"step_tidy_up\",\n",
    "    \"step_streamline\",\n",
    "    \"step_convert_to_hw\",\n",
    "    \"step_create_dataflow_partition\",\n",
    "    \"step_specialize_layers\",\n",
    "    \"step_target_fps_parallelization\", # not necessary due to custom folding configuration\n",
    "    \"step_apply_folding_config\",\n",
    "    \"step_minimize_bit_width\",\n",
    "    \"step_generate_estimate_reports\",\n",
    "    \"step_hw_codegen\",\n",
    "    \"step_hw_ipgen\",\n",
    "    \"step_set_fifo_depths\",\n",
    "    \"step_create_stitched_ip\",\n",
    "    \"step_measure_rtlsim_performance\",\n",
    "    \"step_out_of_context_synthesis\",\n",
    "    \"step_synthesize_bitfile\",\n",
    "    \"step_make_pynq_driver\",\n",
    "    \"step_deployment_package\",\n",
    "]\n",
    "\n",
    "cfg_stitched_ip = build.DataflowBuildConfig(\n",
    "    output_dir          = rtlsim_output_dir,\n",
    "    mvau_wwidth_max     = 80,\n",
    "    #target_fps          = 1000, # not used any more due to custom folding\n",
    "    synth_clk_period_ns = 10.0,\n",
    "    folding_config_file = my_folding_config_file, # new added for custom folding\n",
    "    #steps               = build_steps, # for custom folding\n",
    "    steps               = build_cfg.default_build_dataflow_steps, # default\n",
    "    shell_flow_type     = build_cfg.ShellFlowType.VIVADO_ZYNQ, # new added\n",
    "    board               = \"Pynq-Z2\",\n",
    "    fpga_part           = \"xc7z020clg400-2\",\n",
    "    default_swg_exception = True,\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.STITCHED_IP,\n",
    "        build_cfg.DataflowOutputType.RTLSIM_PERFORMANCE,\n",
    "        build_cfg.DataflowOutputType.OOC_SYNTH,\n",
    "        build_cfg.DataflowOutputType.BITFILE, # shell_flow_type is required\n",
    "        build_cfg.DataflowOutputType.PYNQ_DRIVER,\n",
    "        build_cfg.DataflowOutputType.DEPLOYMENT_PACKAGE,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataflow accelerator from /home/ba/Xilinx/finn-0v10/finn/notebooks/batuhan/QONNX_CNV.onnx\n",
      "Intermediate outputs will be generated in /tmp/finn_dev_ba\n",
      "Final outputs will be generated in output_ipstitch_ooc_rtlsim\n",
      "Build log is at output_ipstitch_ooc_rtlsim/build_dataflow.log\n",
      "Running step: step_qonnx_to_finn [1/19]\n",
      "Running step: step_tidy_up [2/19]\n",
      "Running step: step_streamline [3/19]\n",
      "Running step: step_convert_to_hw [4/19]\n",
      "Running step: step_create_dataflow_partition [5/19]\n",
      "Running step: step_specialize_layers [6/19]\n",
      "Running step: step_target_fps_parallelization [7/19]\n",
      "Running step: step_apply_folding_config [8/19]\n",
      "Running step: step_minimize_bit_width [9/19]\n",
      "Running step: step_generate_estimate_reports [10/19]\n",
      "Running step: step_hw_codegen [11/19]\n",
      "Running step: step_hw_ipgen [12/19]\n",
      "Running step: step_set_fifo_depths [13/19]\n",
      "Running step: step_create_stitched_ip [14/19]\n",
      "Running step: step_measure_rtlsim_performance [15/19]\n",
      "Running step: step_out_of_context_synthesis [16/19]\n",
      "Running step: step_synthesize_bitfile [17/19]\n",
      "Running step: step_make_pynq_driver [18/19]\n",
      "Running step: step_deployment_package [19/19]\n",
      "Completed successfully\n",
      "CPU times: user 28.5 s, sys: 1.02 s, total: 29.6 s\n",
      "Wall time: 25min 17s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "build.build_dataflow_cfg(model_file, cfg_stitched_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assert os.path.exists(rtlsim_output_dir + \"/report/ooc_synth_and_timing.json\")\n",
    "assert os.path.exists(rtlsim_output_dir + \"/report/rtlsim_performance.json\")\n",
    "assert os.path.exists(rtlsim_output_dir + \"/final_hw_config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is e.g. `step_synthesize_bitfile` listed above even though we didn't ask for a bitfile in the output products? This is because we're using the default set of build steps, which includes `step_synthesize_bitfile`. Since its output product is not selected, this step will do nothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the output products, we will find the accelerator exported as a stitched IP block design:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_verilog_srcs.txt\t\t       finn_vivado_stitch_proj.xpr\n",
      "data\t\t\t\t       ip\n",
      "finn_vivado_stitch_proj.cache\t       make_project.sh\n",
      "finn_vivado_stitch_proj.gen\t       make_project.tcl\n",
      "finn_vivado_stitch_proj.hw\t       vivado.jou\n",
      "finn_vivado_stitch_proj.ip_user_files  vivado.log\n",
      "finn_vivado_stitch_proj.srcs\n"
     ]
    }
   ],
   "source": [
    "! ls {rtlsim_output_dir}/stitched_ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have a few reports generated by these output products, different from the ones generated by `ESTIMATE_REPORTS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimate_layer_resources_hls.json  post_synth_resources.json\n",
      "ooc_synth_and_timing.json\t   post_synth_resources.xml\n",
      "post_route_timing.rpt\t\t   rtlsim_performance.json\n"
     ]
    }
   ],
   "source": [
    "! ls {rtlsim_output_dir}/report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `ooc_synth_and_timing.json` we can find the post-synthesis and maximum clock frequency estimate for the accelerator. Note that the clock frequency estimate here tends to be optimistic, since out-of-context synthesis is less constrained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"vivado_proj_folder\": \"/tmp/finn_dev_ba/synth_out_of_context_b9i76j_c/results_finn_design_wrapper\",\n",
      "  \"LUT\": 13644.0,\n",
      "  \"LUTRAM\": 1756.0,\n",
      "  \"FF\": 16955.0,\n",
      "  \"DSP\": 0.0,\n",
      "  \"BRAM\": 98.0,\n",
      "  \"BRAM_18K\": 8.0,\n",
      "  \"BRAM_36K\": 94.0,\n",
      "  \"URAM\": 0.0,\n",
      "  \"Carry\": 518.0,\n",
      "  \"WNS\": 1.442,\n",
      "  \"Delay\": 1.442,\n",
      "  \"vivado_version\": 2022.1,\n",
      "  \"vivado_build_no\": 3526262.0,\n",
      "  \"\": 0,\n",
      "  \"fmax_mhz\": 116.84973124561813,\n",
      "  \"estimated_throughput_fps\": 792.4379560385345\n",
      "}"
     ]
    }
   ],
   "source": [
    "! cat {rtlsim_output_dir}/report/ooc_synth_and_timing.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `rtlsim_performance.json` we can find the steady-state throughput and latency for the accelerator, as obtained by rtlsim. If the DRAM bandwidth numbers reported here are below what the hardware platform is capable of (i.e. the accelerator is not memory-bound), you can expect the same steady-state throughput (excluding any software/driver overheads) in real hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"N_IN_TXNS\": 3072,\n",
      "  \"N_OUT_TXNS\": 10,\n",
      "  \"cycles\": 366924,\n",
      "  \"N\": 1,\n",
      "  \"latency_cycles\": 366924,\n",
      "  \"runtime[ms]\": 3.6692400000000003,\n",
      "  \"throughput[images/s]\": 272.53600200586493,\n",
      "  \"fclk[mhz]\": 100.0,\n",
      "  \"stable_throughput[images/s]\": 272.53600200586493\n",
      "}"
     ]
    }
   ],
   "source": [
    "! cat {rtlsim_output_dir}/report/rtlsim_performance.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's have a look at `final_hw_config.json`. This is the node-by-node hardware configuration determined by the FINN compiler, including FIFO depths, parallelization settings (PE/SIMD) and others. If you want to optimize your build further (the \"advanced\" method we mentioned under \"Configuring the performance\"), you can use this .json file as the `folding_config_file` for a new run to use it as a starting point for further exploration and optimizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Defaults\": {},\n",
      "  \"StreamingFIFO_rtl_0\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 3072,\n",
      "    \"impl_style\": \"rtl\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"ConvolutionInputGenerator_rtl_0\": {\n",
      "    \"SIMD\": 1,\n",
      "    \"parallel_window\": 0,\n",
      "    \"ram_style\": \"distributed\",\n",
      "    \"inFIFODepths\": [\n",
      "      3072\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      3644\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_1\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 3644,\n",
      "    \"impl_style\": \"vivado\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingDataWidthConverter_rtl_0\": {\n",
      "    \"inFIFODepths\": [\n",
      "      3644\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      900\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_2\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 900,\n",
      "    \"impl_style\": \"vivado\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"MVAU_hls_0\": {\n",
      "    \"PE\": 1,\n",
      "    \"SIMD\": 27,\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"resType\": \"auto\",\n",
      "    \"mem_mode\": \"internal_decoupled\",\n",
      "    \"runtime_writeable_weights\": 0,\n",
      "    \"inFIFODepths\": [\n",
      "      900\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      2\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_3\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 2,\n",
      "    \"impl_style\": \"rtl\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingDataWidthConverter_rtl_1\": {\n",
      "    \"inFIFODepths\": [\n",
      "      2\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      350\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_4\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 350,\n",
      "    \"impl_style\": \"vivado\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"ConvolutionInputGenerator_rtl_1\": {\n",
      "    \"SIMD\": 8,\n",
      "    \"parallel_window\": 0,\n",
      "    \"ram_style\": \"distributed\",\n",
      "    \"inFIFODepths\": [\n",
      "      350\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      2\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_5\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 2,\n",
      "    \"impl_style\": \"rtl\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingDataWidthConverter_rtl_2\": {\n",
      "    \"inFIFODepths\": [\n",
      "      2\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      32\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_6\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 32,\n",
      "    \"impl_style\": \"rtl\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"MVAU_hls_1\": {\n",
      "    \"PE\": 8,\n",
      "    \"SIMD\": 72,\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"resType\": \"auto\",\n",
      "    \"mem_mode\": \"internal_decoupled\",\n",
      "    \"runtime_writeable_weights\": 0,\n",
      "    \"inFIFODepths\": [\n",
      "      32\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      2\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_7\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 2,\n",
      "    \"impl_style\": \"rtl\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingDataWidthConverter_rtl_3\": {\n",
      "    \"inFIFODepths\": [\n",
      "      2\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      2\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_8\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 2,\n",
      "    \"impl_style\": \"rtl\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingMaxPool_hls_0\": {\n",
      "    \"PE\": 1,\n",
      "    \"inFIFODepths\": [\n",
      "      2\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      32\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_9\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 32,\n",
      "    \"impl_style\": \"rtl\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingDataWidthConverter_rtl_4\": {\n",
      "    \"inFIFODepths\": [\n",
      "      32\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      256\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_10\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 256,\n",
      "    \"impl_style\": \"rtl\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"ConvolutionInputGenerator_rtl_2\": {\n",
      "    \"SIMD\": 2,\n",
      "    \"parallel_window\": 0,\n",
      "    \"ram_style\": \"distributed\",\n",
      "    \"inFIFODepths\": [\n",
      "      256\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      2\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_11\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 2,\n",
      "    \"impl_style\": \"rtl\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingDataWidthConverter_rtl_5\": {\n",
      "    \"inFIFODepths\": [\n",
      "      2\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      657\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_12\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 657,\n",
      "    \"impl_style\": \"vivado\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"MVAU_hls_2\": {\n",
      "    \"PE\": 2,\n",
      "    \"SIMD\": 72,\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"resType\": \"auto\",\n",
      "    \"mem_mode\": \"internal_decoupled\",\n",
      "    \"runtime_writeable_weights\": 0,\n",
      "    \"inFIFODepths\": [\n",
      "      657\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      71\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_13\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 71,\n",
      "    \"impl_style\": \"rtl\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"ConvolutionInputGenerator_rtl_3\": {\n",
      "    \"SIMD\": 2,\n",
      "    \"parallel_window\": 0,\n",
      "    \"ram_style\": \"distributed\",\n",
      "    \"inFIFODepths\": [\n",
      "      71\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      2\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_14\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 2,\n",
      "    \"impl_style\": \"rtl\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingDataWidthConverter_rtl_6\": {\n",
      "    \"inFIFODepths\": [\n",
      "      2\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      32\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_15\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 32,\n",
      "    \"impl_style\": \"rtl\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"MVAU_hls_3\": {\n",
      "    \"PE\": 4,\n",
      "    \"SIMD\": 72,\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"resType\": \"auto\",\n",
      "    \"mem_mode\": \"internal_decoupled\",\n",
      "    \"runtime_writeable_weights\": 0,\n",
      "    \"inFIFODepths\": [\n",
      "      32\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      2\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_16\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 2,\n",
      "    \"impl_style\": \"rtl\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingDataWidthConverter_rtl_7\": {\n",
      "    \"inFIFODepths\": [\n",
      "      2\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      2\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_17\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 2,\n",
      "    \"impl_style\": \"rtl\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingMaxPool_hls_1\": {\n",
      "    \"PE\": 1,\n",
      "    \"inFIFODepths\": [\n",
      "      2\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      32\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_18\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 32,\n",
      "    \"impl_style\": \"rtl\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingDataWidthConverter_rtl_8\": {\n",
      "    \"inFIFODepths\": [\n",
      "      32\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      2\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_19\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 2,\n",
      "    \"impl_style\": \"rtl\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"ConvolutionInputGenerator_rtl_4\": {\n",
      "    \"SIMD\": 1,\n",
      "    \"parallel_window\": 0,\n",
      "    \"ram_style\": \"distributed\",\n",
      "    \"inFIFODepths\": [\n",
      "      2\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      2\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_20\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 2,\n",
      "    \"impl_style\": \"rtl\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingDataWidthConverter_rtl_9\": {\n",
      "    \"inFIFODepths\": [\n",
      "      2\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      250\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_21\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 250,\n",
      "    \"impl_style\": \"rtl\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"MVAU_hls_4\": {\n",
      "    \"PE\": 1,\n",
      "    \"SIMD\": 32,\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"resType\": \"auto\",\n",
      "    \"mem_mode\": \"internal_decoupled\",\n",
      "    \"runtime_writeable_weights\": 0,\n",
      "    \"inFIFODepths\": [\n",
      "      250\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      2\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_22\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 2,\n",
      "    \"impl_style\": \"rtl\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingDataWidthConverter_rtl_10\": {\n",
      "    \"inFIFODepths\": [\n",
      "      2\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      574\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_23\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 574,\n",
      "    \"impl_style\": \"vivado\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"MVAU_hls_5\": {\n",
      "    \"PE\": 2,\n",
      "    \"SIMD\": 4,\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"resType\": \"auto\",\n",
      "    \"mem_mode\": \"internal_decoupled\",\n",
      "    \"runtime_writeable_weights\": 0,\n",
      "    \"inFIFODepths\": [\n",
      "      574\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      2\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_24\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 2,\n",
      "    \"impl_style\": \"rtl\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingDataWidthConverter_rtl_11\": {\n",
      "    \"inFIFODepths\": [\n",
      "      2\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      54\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_25\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 54,\n",
      "    \"impl_style\": \"rtl\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"MVAU_hls_6\": {\n",
      "    \"PE\": 1,\n",
      "    \"SIMD\": 4,\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"resType\": \"auto\",\n",
      "    \"mem_mode\": \"internal_decoupled\",\n",
      "    \"runtime_writeable_weights\": 0,\n",
      "    \"inFIFODepths\": [\n",
      "      54\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      2\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_26\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 2,\n",
      "    \"impl_style\": \"rtl\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"MVAU_hls_7\": {\n",
      "    \"PE\": 1,\n",
      "    \"SIMD\": 1,\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"resType\": \"auto\",\n",
      "    \"mem_mode\": \"internal_decoupled\",\n",
      "    \"runtime_writeable_weights\": 0,\n",
      "    \"inFIFODepths\": [\n",
      "      2\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      2\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_27\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 2,\n",
      "    \"impl_style\": \"rtl\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  }\n",
      "}"
     ]
    }
   ],
   "source": [
    "! cat {rtlsim_output_dir}/final_hw_config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PYNQ Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! cp unsw_nb15_binarized.npz {final_output_dir}/deploy/driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! cp validate-unsw-nb15.py {final_output_dir}/deploy/driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! ls {final_output_dir}/deploy/driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from shutil import make_archive\n",
    "#make_archive('deploy-on-pynq', 'zip', final_output_dir+\"/deploy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now download the created zipfile (**File -> Open**, mark the checkbox next to the `deploy-on-pynq.zip` and select Download from the toolbar), then copy it to your PYNQ board (for instance via `scp` or `rsync`). Then, run the following commands **on the PYNQ board** to extract the archive and run the validation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "unzip deploy-on-pynq.zip -d finn-cybsec-mlp-demo\n",
    "cd finn-cybsec-mlp-demo/driver\n",
    "sudo python3.6 -m pip install bitstring\n",
    "sudo python3.6 validate-unsw-nb15.py --batchsize 1000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see `Final accuracy: 91.868293` at the end. You may have noticed that the validation doesn't *quite* run at 1M inferences per second. This is because of the Python packing/unpacking and data movement overheads. To see this in more detail, the generated driver includes a benchmarking mode that shows the runtime breakdown:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "sudo python3.6 driver.py --exec_mode throughput_test --bitfile ../bitfile/finn-accel.bit --batchsize 1000\n",
    "cat nw_metrics.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{'runtime[ms]': 1.0602474212646484,\n",
    " 'throughput[images/s]': 943176.0737575893,\n",
    " 'DRAM_in_bandwidth[Mb/s]': 70.7382055318192,\n",
    " 'DRAM_out_bandwidth[Mb/s]': 0.9431760737575894,\n",
    " 'fclk[mhz]': 100.0,\n",
    " 'batch_size': 1000,\n",
    " 'fold_input[ms]': 9.679794311523438e-05,\n",
    " 'pack_input[ms]': 0.060115814208984375,\n",
    " 'copy_input_data_to_device[ms]': 0.002428770065307617,\n",
    " 'copy_output_data_from_device[ms]': 0.0005249977111816406,\n",
    " 'unpack_output[ms]': 0.3773000240325928,\n",
    " 'unfold_output[ms]': 6.818771362304688e-05}```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the various `pack_input/unpack_output` calls show the overhead of packing/unpacking the inputs/outputs to convert from numpy arrays to the bit-contiguous data representation our accelerator expects. The `copy_input_data_to_device` and `copy_output_data_from_device` indicate the cost of moving the data between the CPU and accelerator memories. These overheads can dominate the execution time when running with small batch sizes.\n",
    "\n",
    "Finally, we can see that `throughput[images/s]`, which is the pure hardware throughput without any software and data movement overheads, is close to 1M inferences per second."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
